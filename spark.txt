Apache Sparkâ„¢ is a unified analytics engine for large-scale data processing.
Speed
Run workloads 100x faster.

Apache Spark achieves high performance for both batch and streaming data, using a state-of-the-art DAG scheduler, a query optimizer, and a physical execution engine.


Logistic regression in Hadoop and Spark
Ease of Use
Write applications quickly in Java, Scala, Python, R, and SQL.

Spark offers over 80 high-level operators that make it easy to build parallel apps. And you can use it interactively from the Scala, Python, R, and SQL shells.

df = spark.read.json("logs.json") df.where("age > 21")   .select("name.first").show()
Spark's Python DataFrame API
Read JSON files with automatic schema inference